{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment for colab\n",
    "## upload datasetGenerator.py for preprocessing dataset\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# ! unzip -q \"/content/drive/MyDrive/Colab Notebooks/BVP.zip\"\n",
    "# ! python /content/datasetGenerator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_for_test = 0.2\n",
    "ALL_MOTION = [i for i in range(1, 10)]\n",
    "N_MOTION = len(ALL_MOTION) # Number of output classes\n",
    "T_MAX = 38 # Number of timestamps\n",
    "n_gru_hidden_units = 128\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModule, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=2, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8 * 10 * 10, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "class ConvGRUModel(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes, num_timestamps):\n",
    "        super(ConvGRUModel, self).__init__()\n",
    "        \n",
    "        # CNN module for each input timestamp\n",
    "        self.cnn_modules = nn.ModuleList([\n",
    "            CNNModule() for _ in range(num_timestamps)\n",
    "        ])\n",
    "        \n",
    "        # GRU layers\n",
    "        self.gru = nn.GRU(32, hidden_size, num_layers=num_timestamps, batch_first=True, dropout=0.25)\n",
    "\n",
    "        # Fully connected layer at the output of last GRU\n",
    "        self.fc_out = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # Relu activation for fully connected\n",
    "        self.relu = nn.ReLU()\n",
    "        # Softmax activation for classification\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply CNN module sequentially for each timestamp\n",
    "        x = np.swapaxes(x, 0, 1)\n",
    "        x = [module(xi) for module, xi in zip(self.cnn_modules, x)]\n",
    "        x = torch.stack(x, dim=1)  # Stack along the time dimension\n",
    "        \n",
    "        # GRU layer\n",
    "        x, _ = self.gru(x)\n",
    "\n",
    "        # Apply ReLU activation after the GRU layer\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Fully connected layer at the output of last GRU\n",
    "        x = self.fc_out(x[:, -1, :])\n",
    "        \n",
    "        # Softmax for classification\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "num_clients = 5\n",
    "batch_size = 128\n",
    "client_datasets = {}\n",
    "client_loaders = {}\n",
    "\n",
    "for i in range(1, num_clients + 1):\n",
    "    # Load client data\n",
    "    client_data = torch.load(f'./dataset/new/data{i}.pt')\n",
    "    data = torch.from_numpy(client_data['data']).float()\n",
    "    label = torch.from_numpy(client_data['label']).long()\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    data_train, data_test, label_train, label_test = train_test_split(\n",
    "        data, label, test_size=fraction_for_test, random_state=42\n",
    "    )\n",
    "\n",
    "    train_dataset = TensorDataset(data_train, label_train)\n",
    "    test_dataset = TensorDataset(data_test, label_test)\n",
    "    client_datasets[f'client{i}'] = {'train': train_dataset, 'test':test_dataset}\n",
    "\n",
    "    # Set up data loaders for each client's\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    client_loaders[f'client{i}'] = {'train': train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgAlgorithm:\n",
    "    def __init__(self, global_model, train_loader):\n",
    "        self.global_model = global_model\n",
    "        self.train_loader = train_loader\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def train(self, model, device, train_loader, optimizer, criterion):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        return train_loss, train_accuracy\n",
    "\n",
    "    def test(self, model, device, test_loader, criterion):\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = output.max(1)\n",
    "                correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        return test_loss, test_accuracy\n",
    "\n",
    "    def run(self, num_rounds, num_epochs):\n",
    "        result = []\n",
    "        for round in range(num_rounds):\n",
    "            print(f\"---------- Round {round + 1}/{num_rounds} ----------\")\n",
    "\n",
    "            local_model_updates = []\n",
    "            client_results = {'loss':[], 'accuracy':[]}\n",
    "\n",
    "            for client_id in range(1, len(client_loaders)+1):\n",
    "                print(f\"\\nTraining on Client {client_id}\")\n",
    "\n",
    "                # Create a local copy\n",
    "                local_model = ConvGRUModel(n_gru_hidden_units, N_MOTION, T_MAX).to(self.device)\n",
    "                local_model.load_state_dict(self.global_model.state_dict())\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                optimizer = optim.SGD(local_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "                # Local training\n",
    "                loss, accuracy = [], []\n",
    "                for epoch in range(num_epochs):\n",
    "\n",
    "                    train_loss, train_accuracy = self.train(local_model, self.device, self.train_loader[f'client{client_id}']['train'], optimizer , criterion)\n",
    "                    val_loss, val_accuracy = self.test(local_model, self.device, self.train_loader[f'client{client_id}']['test'], criterion)\n",
    "\n",
    "                    loss.append((train_loss, val_loss))\n",
    "                    accuracy.append((train_accuracy, val_accuracy))\n",
    "                    print(f'        Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%,', \n",
    "                          f' Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "                    \n",
    "                local_model_updates.append(local_model.state_dict())\n",
    "                client_results['loss'].append(loss)\n",
    "                client_results['accuracy'].append(accuracy)\n",
    "\n",
    "            # Weighted average\n",
    "            averaged_state_dict = {}\n",
    "            for key in self.global_model.state_dict():\n",
    "                averaged_state_dict[key] = sum(update[key] for update in local_model_updates) / len(local_model_updates)\n",
    "\n",
    "            self.global_model.load_state_dict(averaged_state_dict)\n",
    "            result.append(client_results)\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_avg_algorithm = FedAvgAlgorithm(global_model=ConvGRUModel(n_gru_hidden_units, N_MOTION, T_MAX).to(device), \n",
    "                                    train_loader=client_loaders\n",
    "                                    )\n",
    "\n",
    "fed_avg_result = fed_avg_algorithm.run(num_rounds=2, num_epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
