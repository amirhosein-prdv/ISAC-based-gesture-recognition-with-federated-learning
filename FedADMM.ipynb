{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment for colab\n",
    "## upload datasetGenerator.py for preprocessing dataset\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# ! unzip -q \"/content/drive/MyDrive/Colab Notebooks/BVP.zip\"\n",
    "# ! python /content/datasetGenerator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_for_test = 0.2\n",
    "num_class = 3\n",
    "ALL_MOTION = [i for i in range(1, num_class+3)]\n",
    "N_MOTION = len(ALL_MOTION) # Number of output classes\n",
    "T_MAX = 38 # Number of timestamps\n",
    "n_gru_hidden_units = 128\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModule, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=2, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8 * 10 * 10, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "class ConvGRUModel(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes, num_timestamps):\n",
    "        super(ConvGRUModel, self).__init__()\n",
    "        \n",
    "        # CNN module for each input timestamp\n",
    "        self.cnn_modules = nn.ModuleList([\n",
    "            CNNModule() for _ in range(num_timestamps)\n",
    "        ])\n",
    "        \n",
    "        # GRU layers\n",
    "        self.gru = nn.GRU(32, hidden_size, num_layers=num_timestamps, batch_first=True, dropout=0.25)\n",
    "\n",
    "        # Fully connected layer at the output of last GRU\n",
    "        self.fc_out = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # Relu activation for fully connected\n",
    "        self.relu = nn.ReLU()\n",
    "        # Softmax activation for classification\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply CNN module sequentially for each timestamp\n",
    "        x = np.swapaxes(x, 0, 1)\n",
    "        x = [module(xi) for module, xi in zip(self.cnn_modules, x)]\n",
    "        x = torch.stack(x, dim=1)  # Stack along the time dimension\n",
    "        \n",
    "        # GRU layer\n",
    "        x, _ = self.gru(x)\n",
    "\n",
    "        # Apply ReLU activation after the GRU layer\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Fully connected layer at the output of last GRU\n",
    "        x = self.fc_out(x[:, -1, :])\n",
    "        \n",
    "        # Softmax for classification\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "num_clients = 5\n",
    "batch_size = 128\n",
    "client_datasets = {}\n",
    "client_loaders = {}\n",
    "\n",
    "for i in range(1, num_clients + 1):\n",
    "    # Load client data\n",
    "    client_data = torch.load(f'./data/data{i}.pt')\n",
    "    data = torch.from_numpy(client_data['data']).float()\n",
    "    label = torch.from_numpy(client_data['label']).long()\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    data_train, data_test, label_train, label_test = train_test_split(\n",
    "        data, label, test_size=fraction_for_test, random_state=42\n",
    "    )\n",
    "\n",
    "    train_dataset = TensorDataset(data_train, label_train)\n",
    "    test_dataset = TensorDataset(data_test, label_test)\n",
    "    client_datasets[f'client{i}'] = {'train': train_dataset, 'test':test_dataset}\n",
    "\n",
    "    # Set up data loaders for each client's\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    client_loaders[f'client{i}'] = {'train': train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FedADMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedADMMAlgorithm:\n",
    "    def __init__(self, global_model, train_loader, rho):\n",
    "        self.global_model = global_model\n",
    "        self.rho = rho\n",
    "        self.train_loader = train_loader\n",
    "        self.num_clients = len(train_loader)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def admm_step(self, local_model, z, u):\n",
    "        # Update local model parameters using ADMM\n",
    "        for local_param, global_param, z_param, u_param in zip(local_model.parameters(),\n",
    "                                                               self.global_model.parameters(),\n",
    "                                                               z.parameters(),\n",
    "                                                               u.parameters()):\n",
    "            local_param.data = (global_param.data + z_param.data - u_param.data) / (2 * self.rho)\n",
    "\n",
    "    def train(self, model, device, train_loader, optimizer, criterion):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        return train_loss, train_accuracy\n",
    "\n",
    "    def test(self, model, device, test_loader, criterion):\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = output.max(1)\n",
    "                correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        return test_loss, test_accuracy\n",
    "    \n",
    "    def run(self, num_rounds, num_epochs):\n",
    "        z = ConvGRUModel(n_gru_hidden_units, N_MOTION, T_MAX).to(self.device)\n",
    "        u = ConvGRUModel(n_gru_hidden_units, N_MOTION, T_MAX).to(self.device)\n",
    "\n",
    "        result = []\n",
    "        for round in range(num_rounds):\n",
    "            print(f\"---------- Round {round + 1}/{num_rounds} ----------\")\n",
    "\n",
    "            # List to store local model updates\n",
    "            local_model_updates = []\n",
    "            client_results = {'loss':[], 'accuracy':[]}\n",
    "\n",
    "            # Iterate over each client\n",
    "            for client_id in range(1, len(client_loaders)+1):\n",
    "                print(f\"\\nTraining on Client {client_id}\")\n",
    "\n",
    "                # Create a local copy\n",
    "                local_model = ConvGRUModel(n_gru_hidden_units, N_MOTION, T_MAX).to(self.device)\n",
    "                local_model.load_state_dict(self.global_model.state_dict())  # Initialize with global model parameters\n",
    "\n",
    "                # Define loss function and optimizer\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                optimizer = optim.SGD(local_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "                # Local training\n",
    "                loss, accuracy = [], []\n",
    "                for epoch in range(num_epochs):\n",
    "\n",
    "                    train_loss, train_accuracy = self.train(local_model, self.device, client_loaders[f'client{client_id}']['train'], optimizer , criterion)\n",
    "                    val_loss, val_accuracy = self.test(local_model, self.device, client_loaders[f'client{client_id}']['test'], criterion)\n",
    "\n",
    "                    loss.append((train_loss, val_loss))\n",
    "                    accuracy.append((train_accuracy, val_accuracy))\n",
    "                    print(f'        Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "                    \n",
    "                local_model_updates.append(local_model.state_dict())\n",
    "                client_results['loss'].append(loss)\n",
    "                client_results['accuracy'].append(accuracy)\n",
    "\n",
    "                # Update local model parameters using ADMM\n",
    "                self.admm_step(local_model, z, u)\n",
    "\n",
    "                # Save the locally updated model parameters\n",
    "                local_model_updates.append(local_model.state_dict())\n",
    "\n",
    "            # Aggregate local model updates using FedADMM\n",
    "            averaged_state_dict = {}\n",
    "            for key in self.global_model.state_dict():\n",
    "                # Weighted average of the model parameters\n",
    "                averaged_state_dict[key] = sum(update[key] for update in local_model_updates) / len(local_model_updates)\n",
    "\n",
    "            # Update the global model with the aggregated parameters\n",
    "            self.global_model.load_state_dict(averaged_state_dict)\n",
    "            result.append(client_results)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_admm = FedADMMAlgorithm( global_model=ConvGRUModel(n_gru_hidden_units, N_MOTION, T_MAX).to(device),\n",
    "                            train_loader=client_loaders,\n",
    "                            rho=0.01\n",
    "                            )\n",
    "\n",
    "fed_admm_result = fed_admm.run(num_rounds=5, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedADMMAlgorithm_:\n",
    "    def __init__(self, global_model, train_loader, rho):\n",
    "        self.train_loader = train_loader\n",
    "        self.num_devices = len(train_loader)\n",
    "        self.rho = rho\n",
    "        self.global_model = global_model\n",
    "        self.local_models = [ConvGRUModel(n_gru_hidden_units, N_MOTION, T_MAX) for _ in range(self.num_devices)]\n",
    "        self.lagrange_multipliers = [torch.zeros_like(param) for param in self.global_model.parameters()]\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.SGD(self.global_model.parameters(), lr=0.01)\n",
    "\n",
    "    def train_local_models(self, dataloaders, num_local_epochs):\n",
    "        for i in range(self.num_devices):\n",
    "            self.local_models[i], _ = self._train_local_model(self.local_models[i], dataloaders[f'client{i+1}']['train'], num_local_epochs)\n",
    "\n",
    "    def _train_local_model(self, model, dataloader, num_local_epochs):\n",
    "        model.train()\n",
    "        for local_epoch in range(num_local_epochs):\n",
    "            for inputs, labels in dataloader:\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                local_loss = loss + (self.rho / 2) * torch.norm(torch.cat([param.flatten() for param in model.parameters()]) - self.lagrange_multipliers[i])**2\n",
    "                local_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "        return model, local_loss.item()\n",
    "\n",
    "    def update_global_model(self):\n",
    "        self.global_model = self._update_global_model(self.local_models)\n",
    "\n",
    "    def _update_global_model(self, local_models):\n",
    "        global_model = ConvGRUModel(n_gru_hidden_units, N_MOTION, T_MAX)\n",
    "        for global_param, local_param in zip(global_model.parameters(), zip(*[local_model.parameters() for local_model in local_models])):\n",
    "            global_param.data = torch.mean(torch.stack(local_param), dim=0)\n",
    "\n",
    "        return global_model\n",
    "\n",
    "    def update_lagrange_multipliers(self):\n",
    "        self.lagrange_multipliers = self._update_lagrange_multipliers(self.lagrange_multipliers, self.local_models, self.global_model)\n",
    "\n",
    "    def _update_lagrange_multipliers(self, lagrange_multipliers, local_models, global_model):\n",
    "        for i in range(len(lagrange_multipliers)):\n",
    "            lagrange_multipliers[i] += self.rho * (torch.cat([param.flatten() for param in local_models[i].parameters()]) - torch.cat([param.flatten() for param in global_model.parameters()]))\n",
    "\n",
    "        return lagrange_multipliers\n",
    "\n",
    "    def run(self, num_rounds, num_local_epochs):\n",
    "        for round_num in range(num_rounds):\n",
    "            print(f\"---------- Round {round_num + 1}/{num_rounds} ----------\")\n",
    "            self.train_local_models(self.train_loader, num_local_epochs)\n",
    "            self.update_global_model()\n",
    "            self.update_lagrange_multipliers()\n",
    "\n",
    "        return self.global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedadmm_algorithm = FedADMMAlgorithm_(global_model=ConvGRUModel(n_gru_hidden_units, N_MOTION, T_MAX).to(device),\n",
    "                                       train_loader=client_loaders,\n",
    "                                       rho=0.1)\n",
    "global_model = fedadmm_algorithm.run(num_rounds=2,\n",
    "                                     num_local_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
