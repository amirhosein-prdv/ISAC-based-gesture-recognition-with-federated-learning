{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment for colab\n",
    "## upload datasetGenerator.py prprocess dataset\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# ! unzip -q \"/content/drive/MyDrive/Colab Notebooks/BVP.zip\"\n",
    "# ! python /content/datasetGenerator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_for_test = 0.2\n",
    "ALL_MOTION = [i for i in range(1, 10)]\n",
    "N_MOTION = len(ALL_MOTION) # Number of output classes\n",
    "T_MAX = 38 # Number of timestamps\n",
    "n_gru_hidden_units = 128\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModule, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=2, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8 * 10 * 10, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "class ConvGRUModel(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes, num_timestamps):\n",
    "        super(ConvGRUModel, self).__init__()\n",
    "        \n",
    "        # CNN module for each input timestamp\n",
    "        self.cnn_modules = nn.ModuleList([\n",
    "            CNNModule() for _ in range(num_timestamps)\n",
    "        ])\n",
    "        \n",
    "        # GRU layers\n",
    "        self.gru = nn.GRU(32, hidden_size, num_layers=num_timestamps, batch_first=True, dropout=0.25)\n",
    "\n",
    "        # Fully connected layer at the output of last GRU\n",
    "        self.fc_out = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        # Relu activation for fully connected\n",
    "        self.relu = nn.ReLU()\n",
    "        # Softmax activation for classification\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply CNN module sequentially for each timestamp\n",
    "        x = np.swapaxes(x, 0, 1)\n",
    "        x = [module(xi) for module, xi in zip(self.cnn_modules, x)]\n",
    "        x = torch.stack(x, dim=1)  # Stack along the time dimension\n",
    "        \n",
    "        # GRU layer\n",
    "        x, _ = self.gru(x)\n",
    "\n",
    "        # Apply ReLU activation after the GRU layer\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Fully connected layer at the output of last GRU\n",
    "        x = self.fc_out(x[:, -1, :])\n",
    "        \n",
    "        # Softmax for classification\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "num_clients = 5\n",
    "batch_size = 128\n",
    "client_datasets = {}\n",
    "client_loaders = {}\n",
    "\n",
    "for i in range(1, num_clients + 1):\n",
    "    # Load client data\n",
    "    client_data = torch.load(f'./dataset/new/data{i}.pt')\n",
    "    data = torch.from_numpy(client_data['data']).float()\n",
    "    label = torch.from_numpy(client_data['label']).long()\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    data_train, data_test, label_train, label_test = train_test_split(\n",
    "        data, label, test_size=fraction_for_test, random_state=42\n",
    "    )\n",
    "\n",
    "    train_dataset = TensorDataset(data_train, label_train)\n",
    "    test_dataset = TensorDataset(data_test, label_test)\n",
    "    client_datasets[f'client{i}'] = {'train': train_dataset, 'test':test_dataset}\n",
    "\n",
    "    # Set up data loaders for each client's\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    client_loaders[f'client{i}'] = {'train': train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalTraining:\n",
    "    def __init__(self, n_gru_hidden_units, N_MOTION, T_MAX, device, client_loaders):\n",
    "        self.n_gru_hidden_units = n_gru_hidden_units\n",
    "        self.N_MOTION = N_MOTION\n",
    "        self.T_MAX = T_MAX\n",
    "        self.device = device\n",
    "        self.client_loaders = client_loaders\n",
    "\n",
    "    def train(self, model, device, train_loader, optimizer, criterion):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        return train_loss, train_accuracy\n",
    "\n",
    "    def test(self, model, device, test_loader, criterion):\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = output.max(1)\n",
    "                correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        return test_loss, test_accuracy\n",
    "\n",
    "    def run(self, num_epochs):\n",
    "        result = []\n",
    "        for user in range(1, num_clients+1):\n",
    "            print(f'- Client {user} training :')\n",
    "            model = ConvGRUModel(self.n_gru_hidden_units, self.N_MOTION, self.T_MAX).to(self.device)\n",
    "            optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "            client_results = {'loss':[], 'accuracy':[]}\n",
    "            for epoch in range(num_epochs):\n",
    "\n",
    "                train_loss, train_accuracy = self.train(model, self.device, self.client_loaders[f'client{user}']['train'], optimizer, criterion)\n",
    "                val_loss, val_accuracy = self.test(model, self.device, self.client_loaders[f'client{user}']['test'], criterion)\n",
    "\n",
    "                loss = (train_loss, val_loss)\n",
    "                accuracy = (train_accuracy, val_accuracy)\n",
    "                print(f'        Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%,', \n",
    "                        f' Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "                    \n",
    "                client_results['loss'].append(loss)\n",
    "                client_results['accuracy'].append(accuracy)\n",
    "\n",
    "                print(f'        Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "                scheduler.step()\n",
    "            \n",
    "            result.append(client_results)\n",
    "            torch.save(model.state_dict(), f'./model/client{user}_model.pth')\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_training = LocalTraining(n_gru_hidden_units, \n",
    "                               N_MOTION, \n",
    "                               T_MAX, \n",
    "                               device, \n",
    "                               client_loaders)\n",
    "local_training.run(num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load best model weights and evaluate on test set\n",
    "# model.load_state_dict(best_model_weights)\n",
    "# test_loss, test_accuracy = test(model, device, test_loader , criterion)\n",
    "\n",
    "# # Plotting training and validation loss and accuracy\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(train_losses, label='Train Loss')\n",
    "# plt.plot(val_losses, label='Validation Loss')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(train_accuracies, label='Train Accuracy')\n",
    "# plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy (%)')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # Print best validation accuracy and test accuracy\n",
    "# print(f'Best Validation Accuracy: {best_val_accuracy:.2f}%')\n",
    "# print(f'Test Accuracy of the final model: {test_accuracy:.2f}%')\n",
    "\n",
    "# # Save the trained model if needed\n",
    "# torch.save(model.state_dict(), './model/client{user}_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centralize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
